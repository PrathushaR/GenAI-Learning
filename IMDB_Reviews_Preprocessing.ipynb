{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzruBuM7scl2DilHkGPV0b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrathushaR/GenAI-Learning/blob/master/IMDB_Reviews_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import IMDB dataset.csv from drive\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Assuming your file is in 'My Drive/IMDB Dataset.csv'\n",
        "# Replace with the actual path if different\n",
        "file_path = '/content/drive/My Drive/IMDB Dataset.csv'\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "df.shape\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "csujzFsvtz6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.head(100)\n"
      ],
      "metadata": {
        "id": "nCYbzlx7Kr0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyKNx316K6C2",
        "outputId": "141f18f5-ab31-483f-f5ea-1d34b7a481b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYDwxDjxKlOq",
        "outputId": "9e377b22-4fe1-49b1-e6f9-44f6ff4adf71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['review'][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-uOvvukLRYi",
        "outputId": "862c72f8-c06c-4023-9be1-af26ed68e144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Print 3rd review\n",
        "\n",
        "# import pandas as pd\n",
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Assuming your file is in 'My Drive/IMDB Dataset.csv'\n",
        "# # Replace with the actual path if different\n",
        "# file_path = '/content/drive/My Drive/IMDB Dataset.csv'\n",
        "\n",
        "# df = pd.read_csv(file_path)\n",
        "\n",
        "# # Accessing the 3rd review (index 2 because Python uses 0-based indexing)\n",
        "# try:\n",
        "#   third_review = df['review'][2]\n",
        "#   print(third_review)\n",
        "# except IndexError:\n",
        "#   print(\"The DataFrame does not have a 3rd review.\")\n",
        "# except KeyError:\n",
        "#     print(\"The DataFrame does not have a 'review' column.\")"
      ],
      "metadata": {
        "id": "zAe9s4NPL2PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].str.lower()\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "27sOG35jLJt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create code to remove html tags from the data\n",
        "\n",
        "import re\n",
        "\n",
        "def remove_html_tags(text):\n",
        "  clean = re.compile('<.*?>')\n",
        "  return re.sub(clean, '', text)\n",
        "\n",
        "df['review'] = df['review'].apply(remove_html_tags)\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "qLBh6zWEbmbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Generate code to remove urls from the review text\n",
        "\n",
        "def remove_urls(text):\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub(r'', text)\n",
        "\n",
        "df['review'] = df['review'].apply(remove_urls)\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "RKins4HkskTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Code to remove punctuations\n",
        "\n",
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator)\n",
        "\n",
        "df['review'] = df['review'].apply(remove_punctuation)\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "36YAi983su3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Generate Code to handle chat conversations by expanding acronyms\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import re\n",
        "import string\n",
        "\n",
        "# Define a dictionary of acronyms and their expansions\n",
        "acronym_expansions = {\n",
        "    \"lol\": \"laughing out loud\",\n",
        "    \"brb\": \"be right back\",\n",
        "    \"omg\": \"oh my god\",\n",
        "    \"imo\": \"in my opinion\",\n",
        "    \"btw\": \"by the way\",\n",
        "    'AFAIK':'As Far As I Know',\n",
        "    'AFK':'Away From Keyboard',\n",
        "    'ASAP':'As Soon As Possible',\n",
        "    \"FYI\": \"For Your Information\",\n",
        "    \"ASAP\": \"As Soon As Possible\",\n",
        "    \"BRB\": \"Be Right Back\",\n",
        "    \"BTW\": \"By The Way\",\n",
        "    \"OMG\": \"Oh My God\",\n",
        "    \"IMO\": \"In My Opinion\",\n",
        "    \"LOL\": \"Laugh Out Loud\",\n",
        "    \"TTYL\": \"Talk To You Later\",\n",
        "    \"GTG\": \"Got To Go\",\n",
        "    \"TTYT\": \"Talk To You Tomorrow\",\n",
        "    \"IDK\": \"I Don't Know\",\n",
        "    \"TMI\": \"Too Much Information\",\n",
        "    \"IMHO\": \"In My Humble Opinion\",\n",
        "    \"ICYMI\": \"In Case You Missed It\",\n",
        "    \"AFAIK\": \"As Far As I Know\",\n",
        "    \"BTW\": \"By The Way\",\n",
        "    \"FAQ\": \"Frequently Asked Questions\",\n",
        "    \"TGIF\": \"Thank God It's Friday\",\n",
        "    \"FYA\": \"For Your Action\",\n",
        "    \"ICYMI\": \"In Case You Missed It\",\n",
        "    # Add more acronyms and their expansions as needed\n",
        "}\n",
        "\n",
        "acronym_expansions = {k.lower(): v for k, v in acronym_expansions.items()}\n",
        "\n",
        "def expand_acronyms(text):\n",
        "    words = text.split()\n",
        "    expanded_words = []\n",
        "    for word in words:\n",
        "        if word.lower() in acronym_expansions:\n",
        "            expanded_words.append(acronym_expansions[word.lower()])\n",
        "        else:\n",
        "            expanded_words.append(word)\n",
        "    return \" \".join(expanded_words)\n",
        "\n",
        "# Example usage with your existing DataFrame (assuming 'df' and 'review' column exist)\n",
        "df['review'] = df['review'].apply(expand_acronyms)\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "mBxscVCCtB-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Generate code to remove stop words from reviews\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "df['review'] = df['review'].apply(remove_stopwords)\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "lhtEuzaOtpT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Emojis"
      ],
      "metadata": {
        "id": "3cEP6vIHz6zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Remove emojis\n",
        "\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "df['review'] = df['review'].apply(remove_emoji)\n",
        "print(df['review'][2])\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "KM-1Voc8z_Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "GCL7YJNv1cg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTk"
      ],
      "metadata": {
        "id": "Bd_Mcftn2Jq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Tokenize \"thought wonderful way spend time hot summer weekend sitting air conditioned theater watching lighthearted comedy plot simplistic dialogue witty characters likable even well bread suspected serial killer may disappointed realize match point 2 risk addiction thought proof woody allen still fully control style many us grown lovethis id laughed one woodys comedies years dare say decade ive never impressed scarlet johanson managed tone sexy image jumped right average spirited young womanthis may crown jewel career wittier devil wears prada interesting superman great comedy go see friends\" using nltk\n",
        "\n",
        "import nltk\n",
        "# Download the 'punkt_tab' resource\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"thought wonderful way spend time hot summer weekend sitting air conditioned theater watching lighthearted comedy plot simplistic dialogue witty characters likable even well bread suspected serial killer may disappointed realize match point 2 risk addiction thought proof woody allen still fully control style many us grown lovethis id laughed one woodys comedies years dare say decade ive never impressed scarlet johanson managed tone sexy image jumped right average spirited young womanthis may crown jewel career wittier devil wears prada interesting superman great comedy go see friends\"\n",
        "tokens = word_tokenize(text)\n",
        "tokens"
      ],
      "metadata": {
        "id": "vJzGFswt1fkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spacy"
      ],
      "metadata": {
        "id": "QrS3GBCi2nCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Generate code to tokenize the same sentence with spacy\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Load the spaCy English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"thought wonderful way spend time hot summer weekend sitting air conditioned theater watching lighthearted comedy plot simplistic dialogue witty characters likable even well bread suspected serial killer may disappointed realize match point 2 risk addiction thought proof woody allen still fully control style many us grown lovethis id laughed one woodys comedies years dare say decade ive never impressed scarlet johanson managed tone sexy image jumped right average spirited young womanthis may crown jewel career wittier devil wears prada interesting superman great comedy go see friends\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Get the tokens\n",
        "spacy_tokens = [token.text for token in doc]\n",
        "\n",
        "# Print the tokens\n",
        "spacy_tokens"
      ],
      "metadata": {
        "id": "jLDEsWCD2lWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemmer"
      ],
      "metadata": {
        "id": "0J0HNjUy3DFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: For the text \"\"thought wonderful way spend time hot summer weekend sitting air conditioned theater watching lighthearted comedy plot simplistic dialogue witty characters likable even well bread suspected serial killer may disappointed realize match point 2 risk addiction thought proof woody allen still fully control style many us grown lovethis id laughed one woodys comedies years dare say decade ive never impressed scarlet johanson managed tone sexy image jumped right average spirited young womanthis may crown jewel career wittier devil wears prada interesting superman great comedy go see friends\" do stemmer\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "def stem_words(text):\n",
        "    return \" \".join([ps.stem(word) for word in text.split()])\n",
        "\n",
        "stem_words(text)"
      ],
      "metadata": {
        "id": "abBf-DIF3Cx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemetization"
      ],
      "metadata": {
        "id": "h99hupax3GGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Lemetize the text\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_words(text):\n",
        "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "\n",
        "print(lemmatize_words(text))"
      ],
      "metadata": {
        "id": "y1XcsRZW3FMv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}